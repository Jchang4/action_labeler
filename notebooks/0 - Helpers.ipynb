{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add the action_labeler package to Python path\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from action_labeler.helpers.detections_helpers import (\n",
    "    ultralytics_labels_to_xywh,\n",
    "    xywhs_to_xyxys,\n",
    "    xyxys_to_xywhs,\n",
    "    xyxys_to_masks,\n",
    ")\n",
    "\n",
    "from action_labeler.helpers.yolov8_dataset import get_data_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import rmtree\n",
    "\n",
    "rmtree(\"./runs/detect\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/justin/machine_learning/yolo/action_labeler/notebooks/samples/dog_laying_down_1.jpg: 448x640 2 dogs, 36.1ms\n",
      "Speed: 3.8ms preprocess, 36.1ms inference, 113.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "1 label saved to runs/detect/predict/labels\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolo12n.pt\")\n",
    "\n",
    "results = model.predict(\n",
    "    \"./samples/dog_laying_down_1.jpg\",\n",
    "    save_txt=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       " obb: None\n",
       " orig_img: array([[[105, 104,  70],\n",
       "         [102, 100,  69],\n",
       "         [ 97,  97,  67],\n",
       "         ...,\n",
       "         [ 23,  30,  27],\n",
       "         [ 23,  30,  27],\n",
       "         [ 23,  30,  27]],\n",
       " \n",
       "        [[104, 103,  69],\n",
       "         [102, 100,  69],\n",
       "         [ 96,  96,  66],\n",
       "         ...,\n",
       "         [ 23,  30,  27],\n",
       "         [ 23,  30,  27],\n",
       "         [ 23,  30,  27]],\n",
       " \n",
       "        [[103, 102,  68],\n",
       "         [101,  99,  68],\n",
       "         [ 96,  96,  66],\n",
       "         ...,\n",
       "         [ 23,  29,  28],\n",
       "         [ 22,  28,  27],\n",
       "         [ 22,  28,  27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 56, 102,  73],\n",
       "         [ 48,  99,  71],\n",
       "         [ 33,  93,  63],\n",
       "         ...,\n",
       "         [124, 148, 148],\n",
       "         [109, 137, 138],\n",
       "         [ 90, 120, 125]],\n",
       " \n",
       "        [[ 61, 105,  76],\n",
       "         [ 53, 104,  76],\n",
       "         [ 38,  97,  69],\n",
       "         ...,\n",
       "         [135, 158, 154],\n",
       "         [123, 147, 145],\n",
       "         [100, 130, 131]],\n",
       " \n",
       "        [[ 60, 103,  76],\n",
       "         [ 55, 103,  77],\n",
       "         [ 41,  99,  71],\n",
       "         ...,\n",
       "         [136, 158, 153],\n",
       "         [123, 148, 144],\n",
       "         [101, 129, 129]]], shape=(768, 1151, 3), dtype=uint8)\n",
       " orig_shape: (768, 1151)\n",
       " path: '/home/justin/machine_learning/yolo/action_labeler/notebooks/samples/dog_laying_down_1.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 3.844939998089103, 'inference': 36.05701899869018, 'postprocess': 113.77456600166624}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyxys = xywhs_to_xyxys(results[0].boxes.xywhn, results[0].orig_shape[::-1])\n",
    "expected_xyxys = results[0].boxes.xyxy.tolist()\n",
    "\n",
    "np.testing.assert_allclose(\n",
    "    np.array(xyxys),\n",
    "    np.array(expected_xyxys),\n",
    "    rtol=1e-5,\n",
    "    atol=1e-5,\n",
    "    err_msg=f\"xyxys and expected_xyxys not close enough\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xywhs = xyxys_to_xywhs(results[0].boxes.xyxy, results[0].orig_shape[::-1])\n",
    "expected_xywhs = results[0].boxes.xywhn.tolist()\n",
    "\n",
    "np.testing.assert_allclose(\n",
    "    np.array(xywhs),\n",
    "    np.array(expected_xywhs),\n",
    "    rtol=1e-5,\n",
    "    atol=1e-5,\n",
    "    err_msg=f\"xywhs and expected_xywhs not close enough\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "labels_path = Path(\"./runs/detect/predict/labels\")\n",
    "\n",
    "xywhs = []\n",
    "\n",
    "for label_path in labels_path.glob(\"*.txt\"):\n",
    "    xywhs.append(ultralytics_labels_to_xywh(label_path))\n",
    "\n",
    "xywhs = np.array(xywhs)[0]  # ignore batch dimension\n",
    "expected_xywhs = results[0].boxes.xywhn.tolist()\n",
    "\n",
    "np.testing.assert_allclose(\n",
    "    xywhs,\n",
    "    expected_xywhs,\n",
    "    rtol=1e-5,\n",
    "    atol=1e-5,\n",
    "    err_msg=f\"xywhs and expected_xywhs not close enough\",\n",
    ")\n",
    "\n",
    "\n",
    "np.testing.assert_allclose(\n",
    "    xywhs_to_xyxys(xywhs, results[0].orig_shape[::-1]),\n",
    "    results[0].boxes.xyxy.tolist(),\n",
    "    rtol=1e-4,\n",
    "    atol=1e-4,\n",
    "    err_msg=f\"xyxys and expected_xyxys not close enough\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks = xyxys_to_masks(results[0].boxes.xyxy, results[0].orig_shape[::-1])\n",
    "# masks = np.array(masks)\n",
    "\n",
    "# # Ensure each mask is the same size as image\n",
    "# # Ignore batch dimension\n",
    "# assert (\n",
    "#     masks.shape[1:] == results[0].orig_shape[::-1]\n",
    "# ), f\"Masks shape {masks.shape[1:]} does not match image shape {results[0].orig_shape[::-1]}\"\n",
    "\n",
    "# # Total number of Trues equals height * width of xyxys\n",
    "# for mask, xyxy in zip(masks, results[0].boxes.xyxy):\n",
    "#     total_trues = np.sum(mask)\n",
    "#     expected_trues = (xyxy[2] - xyxy[0]) * (xyxy[3] - xyxy[1])\n",
    "#     assert (\n",
    "#         total_trues == expected_trues\n",
    "#     ), f\"Total number of Trues {total_trues} does not match expected {expected_trues}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: samples\n",
      "Class Names:\n",
      "0: laying down\n",
      "1: moving\n",
      "2: sitting\n",
      "3: standing still\n",
      "Number of classes: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'names': ['laying down', 'moving', 'sitting', 'standing still'],\n",
       " 'path': 'dog_dataset_balanced',\n",
       " 'train': 'train/images',\n",
       " 'val': 'valid/images'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_yaml(\"./samples\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from action_labeler.helpers.detections_helpers import Detection\n",
    "\n",
    "d = Detection.from_ultralytics(results[0])\n",
    "\n",
    "np.testing.assert_allclose(\n",
    "    d.image_size,\n",
    "    results[0].orig_shape[::-1],\n",
    "    rtol=1e-5,\n",
    "    atol=1e-5,\n",
    "    err_msg=f\"image_size and expected_image_size not close enough\",\n",
    ")\n",
    "\n",
    "np.testing.assert_allclose(\n",
    "    d.xyxy,\n",
    "    results[0].boxes.xyxy.cpu().numpy(),\n",
    "    rtol=1e-5,\n",
    "    atol=1e-5,\n",
    "    err_msg=f\"xyxy and expected_xyxy not close enough\",\n",
    ")\n",
    "\n",
    "np.testing.assert_allclose(\n",
    "    d.xywhn,\n",
    "    results[0].boxes.xywhn.cpu().numpy(),\n",
    "    rtol=1e-5,\n",
    "    atol=1e-5,\n",
    "    err_msg=f\"xywhn and expected_xywhn not close enough\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
